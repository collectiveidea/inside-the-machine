<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <link href="stylesheets/pygments.css" media="screen" rel="stylesheet" type="text/css" />
    <link href="stylesheets/softcover.css" media="screen" rel="stylesheet" type="text/css" />
    <link href="stylesheets/custom.css" media="screen" rel="stylesheet" type="text/css" />
    
    <title>inside_the_machine</title>
    
      <script type="text/x-mathjax-config">
              MathJax.Hub.Config({
        "HTML-CSS": {
          availableFonts: ["TeX"],
        },
        TeX: {
          extensions: ["AMSmath.js", "AMSsymbols.js"],
          equationNumbers: {
            autoNumber: "AMS",
            
          },
          Macros: {
            PolyTeX:    "Poly{\\TeX}",
            PolyTeXnic: "Poly{\\TeX}nic",
            "softcover": "\\texttt{softcover}",
"unitvec": ["{\\hat #1}", 1]
          }
        },
        showProcessingMessages: false,
        messageStyle: "none",
        imageFont: null
      });

      </script>
      <script type="text/javascript" src="MathJax/MathJax.js?config=TeX-AMS-MML_SVG"></script>
    
  </head>
  <body>
    
    <div id="book">
      <div id="frontmatter" data-number="0"><div id="title_page"><h1 class="title">Inside the Machine, Second Edition</h1><h1 class="subtitle">An Illustrated Introduction to Microprocessors and Computer Architecture</h1><h2 class="author">Jon Stokes</h2></div>
<h1 class="contents">Contents</h1><div id="table_of_contents"><ul><li class="chapter-star"><a href="#preface" class="heading hyperref">Preface</a></li><li class="chapter"><a href="#cha-basic_computing_concepts" class="heading hyperref"><span class="number">Chapter 1 </span>Basic Computing Concepts</a></li><li><ul><li class="section"><a href="#sec-calculator_model" class="heading hyperref"><span class="number">1.1 </span>The Calculator Model of Computing</a></li><li class="section"><a href="#cid3" class="heading hyperref"><span class="number">1.2 </span>The File-Clerk Model of Computing</a></li><li><ul><li class="subsection"><a href="#uid6" class="heading hyperref"><span class="number">1.2.1 </span>The Stored-Program Computer</a></li><li class="subsection"><a href="#uid13" class="heading hyperref"><span class="number">1.2.2 </span>Refining the File-Clerk Model</a></li></ul></li><li class="section"><a href="#cid4" class="heading hyperref"><span class="number">1.3 </span>The Register File</a></li><li class="section"><a href="#cid5" class="heading hyperref"><span class="number">1.4 </span>RAM: When the Registers Alone Don’t Cut It</a></li><li><ul><li class="subsection"><a href="#uid22" class="heading hyperref"><span class="number">1.4.1 </span>The File-Clerk Model Revisited and Expanded</a></li><li class="subsection"><a href="#uid23" class="heading hyperref"><span class="number">1.4.2 </span>An Example: Adding Two Numbers</a></li></ul></li><li class="section"><a href="#cid6" class="heading hyperref"><span class="number">1.5 </span>A Closer Look at the Code Stream: the Program</a></li><li><ul><li class="subsection"><a href="#uid33" class="heading hyperref"><span class="number">1.5.1 </span>General Instruction Types</a></li><li class="subsection"><a href="#uid37" class="heading hyperref"><span class="number">1.5.2 </span>The DLW-1’s Basic Architecture and Instruction Formats</a></li></ul></li><li class="section"><a href="#cid7" class="heading hyperref"><span class="number">1.6 </span>A Closer Look at Memory Accesses: Register vs.<span class="intersentencespace"></span> Immediate</a></li><li><ul><li class="subsection"><a href="#uid42" class="heading hyperref"><span class="number">1.6.1 </span>Immediate Values</a></li><li class="subsection"><a href="#uid45" class="heading hyperref"><span class="number">1.6.2 </span>Register-Relative Addressing</a></li></ul></li></ul></li><li class="chapter"><a href="#cha-the_mechanics_of_program_execution" class="heading hyperref"><span class="number">Chapter 2 </span>The Mechanics of Program Execution</a></li><li><ul><li class="section"><a href="#cid9" class="heading hyperref"><span class="number">2.1 </span>Opcodes and Machine Language</a></li><li><ul><li class="subsection"><a href="#uid46" class="heading hyperref"><span class="number">2.1.1 </span>Machine Language on the DLW-1</a></li><li class="subsection"><a href="#uid48" class="heading hyperref"><span class="number">2.1.2 </span>Binary Encoding of Arithmetic Instructions</a></li><li class="subsection"><a href="#uid51" class="heading hyperref"><span class="number">2.1.3 </span>Binary Encoding of Memory Access Instructions</a></li><li class="subsection"><a href="#uid58" class="heading hyperref"><span class="number">2.1.4 </span>Translating an Example Program into Machine Language</a></li></ul></li><li class="section"><a href="#cid10" class="heading hyperref"><span class="number">2.2 </span>The Programming Model and the ISA</a></li><li><ul><li class="subsection"><a href="#uid59" class="heading hyperref"><span class="number">2.2.1 </span>The Programming Model</a></li><li class="subsection"><a href="#uid60" class="heading hyperref"><span class="number">2.2.2 </span>The Instruction Register and Program Counter</a></li><li class="subsection"><a href="#uid64" class="heading hyperref"><span class="number">2.2.3 </span>The Instruction Fetch: Loading the Instruction Register</a></li><li class="subsection"><a href="#uid65" class="heading hyperref"><span class="number">2.2.4 </span>Running a Simple Program: the Fetch-Execute Loop</a></li></ul></li><li class="section"><a href="#cid11" class="heading hyperref"><span class="number">2.3 </span>The Clock</a></li><li class="section"><a href="#cid12" class="heading hyperref"><span class="number">2.4 </span>Branch Instructions</a></li><li><ul><li class="subsection"><a href="#uid84" class="heading hyperref"><span class="number">2.4.1 </span>Unconditional Branch</a></li><li class="subsection"><a href="#uid85" class="heading hyperref"><span class="number">2.4.2 </span>Conditional Branch</a></li></ul></li><li class="section"><a href="#cha-pipelined_execution" class="heading hyperref"><span class="number">2.5 </span>Excursus: Booting Up</a></li></ul></li></ul></div>
<div class="chapter-star" id="preface"><h1><a href="#preface" class="heading hyperref">Preface</a></h1>
<p>This is a work in progress, and I’ll be posting a chapter at a time.</p>
<p>Also, I don’t have an electronic copy handy of the book’s real preface, so that will come later.</p>
<p><a href="http://collectiveidea.com/blog/archives/2015/09/15/inside-the-machine-v20-coming-soon-with-more-arm/" target="_blank">More info</a>.</p>
<p><a href="https://github.com/collectiveidea/inside_the_machine" target="_blank">Github repo</a></p>
</div></div>

<div id="cha-basic_computing_concepts" data-tralics-id="cid1" class="chapter" data-number="1"><h1><a href="#cha-basic_computing_concepts" class="heading hyperref"><span class="number">Chapter 1 </span>Basic Computing Concepts</a></h1>
<p>Modern computers come in all shapes and sizes, and they aid us in a million different types of tasks ranging from the serious, like air traffic control and cancer research, to the not-so-serious, like computer gaming and photograph retouching.<span class="intersentencespace"></span> But as diverse as computers are in their outward forms and in the uses to which they’re put, they’re all amazingly similar in basic function.<span class="intersentencespace"></span> All of them rely on a limited repertoire of technologies that enable them do the myriad kinds of miracles we’ve come to expect from them.</p>
<p>At the heart of the modern computer is the <em>microprocessor</em>–also commonly called the <em>central processing unit (CPU)</em>–a tiny, square sliver of silicon that’s etched with a microscopic network of gates and channels through which electricity flows.<span class="intersentencespace"></span> This network of gates (<em>transistors</em>) and channels (<em>wires</em> or <em>lines</em>) is a very small version of the kind of circuitry that we’ve all seen when cracking open a television remote or an old radio.<span class="intersentencespace"></span> In short, the microprocessor isn’t just the “heart” of a modern computer–it’s a computer in and of itself.<span class="intersentencespace"></span> Once you understand how this tiny computer works, you’ll have a thorough grasp of the fundamental concepts that underlie all of modern computing, from the aforementioned air traffic control system to the silicon brain that controls the brakes on a luxury car.</p>
<p>This chapter will introduce you to the microprocessor, and you’ll begin to get a feel for just how straightforward computers really are.<span class="intersentencespace"></span> You need master only a few fundamental concepts before you explore the micro- processor technologies detailed in the later chapters of this book.</p>
<p>To that end, this chapter builds the general conceptual framework on which I’ll hang the technical details covered in the rest of the book.<span class="intersentencespace"></span> Both newcomers to the study of computer architecture and more advanced readers are encouraged to read this chapter all the way through, because its abstractions and generalizations furnish the large conceptual “boxes” in which I’ll later place the specifics of particular architectures.</p>
</div>
<div id="sec-calculator_model" data-tralics-id="cid2" class="section" data-number="1.1"><h2><a href="#sec-calculator_model" class="heading hyperref"><span class="number">1.1 </span>The Calculator Model of Computing</a></h2>
<p><a href="#fig-1-1" class="hyperref">Figure <span class="ref">1.1</span></a> is an abstract graphical representation of what a computer does.<span class="intersentencespace"></span> In a nutshell, a computer takes a stream of instructions (code) and a stream of data as input, and it produces a stream of results as output.<span class="intersentencespace"></span> For the purposes of our initial discussion, we can generalize by saying that the <em>code stream</em> consists of different types of arithmetic operations and the <em>data stream</em> consists of the data on which those operations operate.<span class="intersentencespace"></span> The <em>results stream</em>, then, is made up of the results of these operations.<span class="intersentencespace"></span> You could also say that the results stream begins to flow when the operators in the code stream are carried out on the operands in the data stream.</p>
<div class="center figure" id="fig-1-1" data-tralics-id="uid1" data-number="1.1">
<div class="graphics image"><img src="images/figure_1-1.png" alt="images/figure_1-1" /></div><div class="caption"><span class="header">Figure 1.1: </span><span class="description">A simple representation of a general-purpose computer.
</span></div></div>
<div class="aside" id="aside-note_1-1" data-tralics-id="uid2" data-number="1.1"><div class="heading"><span class="number">Box 1.1.</span> 
</div>
<p class="noindent"><a href="#fig-1-1" class="hyperref">Figure <span class="ref">1.1</span></a> is my own variation on the traditional way of representing a processor’s arithmetic logic unit (ALU), which is the part of the processor that does the addition, subtraction, and so on, of numbers.<span class="intersentencespace"></span> However, instead of showing two operands entering the top ports and a result exiting the bottom port (as is the custom in the literature), I’ve depicted code and data streams entering the top ports and a results stream leaving the bottom port.</p>

</div><p>To illustrate this point, imagine that one of those little black boxes in the code stream of <a href="#fig-1-1" class="hyperref">Figure <span class="ref">1.1</span></a> is an addition operator (a + sign) and that two of the white data boxes contain two integers to be added together, as shown in <a href="#fig-1-2" class="hyperref">Figure <span class="ref">1.2</span></a>.</p>
<div class="center figure" id="fig-1-2" data-tralics-id="uid3" data-number="1.2">
<div class="graphics image"><img src="images/figure_1-2.png" alt="images/figure_1-2" /></div><div class="caption"><span class="header">Figure 1.2: </span><span class="description">Instructions are combined with data to produce results.
</span></div></div>
<p>You might think of these black-and-white boxes as the keys on a calculator—with the white keys being numbers and the black keys being operators—the gray boxes are the results that appear on the calculator’s screen.<span class="intersentencespace"></span> Thus the two input streams (the code stream and the data stream) represent sequences of key presses (arithmetic operator keys and number keys), while the output stream represents the resulting sequence of numbers displayed on the calculator’s screen.</p>
<p>The kind of simple calculation described above represents the sort of thing that we intuitively think computers do: like a pocket calculator, the computer takes numbers and arithmetic operators (such as +, –, ÷, ×, etc.)<span class="intersentencespace"></span> as input, performs the requested operation, and then displays the results.<span class="intersentencespace"></span> These results might be in the form of pixel values that make up a rendered scene in a computer game, or they might be dollar values in a financial spreadsheet.</p>
</div>
<div id="cid3" data-tralics-id="cid3" class="section" data-number="1.2"><h2><a href="#cid3" class="heading hyperref"><span class="number">1.2 </span>The File-Clerk Model of Computing</a></h2>
<p>The “calculator” model of computing, while useful in many respects, isn’t the only or even the best way to think about what computers do.<span class="intersentencespace"></span> As an alternative, consider the following definition of a computer:</p>
<blockquote class="quotation"><p class="quote">A computer is a device that shuffles numbers around from place to place, reading, writing, erasing, and rewriting different numbers in different locations according to a set of inputs, a fixed set of rules for processing those inputs, and the prior history of all the inputs that the computer has seen since it was last reset, until a predefined set of criteria are met that cause the computer to halt.<span class="intersentencespace"></span></p>
</blockquote><p>We might, after Richard Feynman, call this idea of a computer as a reader, writer, and modifier of numbers the “file-clerk” model of computing (as opposed to the aforementioned calculator model).<span class="intersentencespace"></span> In the file-clerk model, the computer accesses a large (theoretically infinite) store of sequentially arranged numbers for the purpose of altering that store to achieve a desired result.<span class="intersentencespace"></span> Once this desired result is achieved, the computer halts so that the now-modified store of numbers can be read and interpreted by humans.</p>
<p>The file-clerk model of computing might not initially strike you as all that useful, but as this chapter progresses, you’ll begin to understand how important it is.<span class="intersentencespace"></span> This way of looking at computers is powerful because it emphasizes the end product of computation rather than the computation itself.<span class="intersentencespace"></span> After all, the purpose of computers isn’t just to compute in the abstract, but to produce usable results from a given data set.</p>
<div class="aside" id="aside-note_1-2" data-tralics-id="uid4" data-number="1.2"><div class="heading"><span class="number">Box 1.2.</span> 
</div>
<p class="noindent">Those who’ve studied computer science will recognize in the preceding description the beginnings of a discussion of a Turing machine.<span class="intersentencespace"></span> The Turing machine is, however, too abstract for our purposes here, so I won’t actually describe one.<span class="intersentencespace"></span> The description that I develop here sticks closer to the classic Reduced Instruction Set Computing (RISC) load-store model, where the computer is “fixed” along with the storage.<span class="intersentencespace"></span> The Turing model of a computer as a movable read-write head (with a state table) traversing a linear “tape” is too far from real-life hardware organization to be anything but confusing in this discussion.</p>

</div><p>In other words, what matters in computing is not that you did some math, but that you started with a body of numbers, applied a sequence of operations to it, and got a body of results.<span class="intersentencespace"></span> Those results could, again, represent pixel values for a rendered scene or an environmental snapshot in a weather simulation.<span class="intersentencespace"></span> Indeed, the idea that a computer is a device that transforms one set of numbers into another should be intuitively obvious to anyone who has ever used a Photoshop filter.<span class="intersentencespace"></span> Once we understand computers not in terms of the math they do, but in terms of the numbers they move and modify, we can begin to get a fuller picture of how they operate.</p>
<p>In a nutshell, a computer is a device that reads, modifies, and writes sequences of numbers.<span class="intersentencespace"></span> These three functions–read, modify, and write–are the three most fundamental functions that a computer performs, and all of the machine’s components are designed to aid in carrying them out.<span class="intersentencespace"></span> This read-modify-write sequence is actually inherent in the three central bullet points of our initial file-clerk definition of a computer.<span class="intersentencespace"></span> Here is the sequence mapped explicitly onto the file-clerk definition:</p>
<blockquote class="quotation"><p class="quote">A computer is a device that shuffles numbers around from place to place, reading, writing, erasing, and rewriting different numbers in different locations according to a set of inputs [read], a fixed set of rules for processing those inputs [modify], and the prior history of all the inputs that the computer has seen since it was last reset [write], until a predefined set of criteria are met that cause the computer to halt.<span class="intersentencespace"></span></p>
</blockquote><p>That sums up what a computer does.<span class="intersentencespace"></span> And, in fact, that’s all a computer does.<span class="intersentencespace"></span> Whether you’re playing a game or listening to music, everything that’s going on under the computer’s hood fits into this model.</p>
<div class="aside" id="aside-note_1-2" data-tralics-id="uid5" data-number="1.3"><div class="heading"><span class="number">Box 1.3.</span> 
</div>
<p class="noindent">All of this is fairly simple so far, and I’ve even been a bit repetitive with the explanations to drive home the basic read-modify-write structure of all computer operations.<span class="intersentencespace"></span> It’s important to grasp this structure in its simplicity, because as we increase our computing model’s level of complexity, we’ll see this structure repeated at every level.</p>

</div>
<div id="uid6" data-tralics-id="uid6" class="subsection" data-number="1.2.1"><h3><a href="#uid6" class="heading hyperref"><span class="number">1.2.1 </span>The Stored-Program Computer</a></h3>
<p>All computers consist of at least three fundamental types of structures needed
to carry out the read-modify-write sequence:</p>
<ul>
<li>Storage
To say that a computer “reads” and “writes” numbers implies that there is at least one number-holding structure that it reads from and writes to.<span class="intersentencespace"></span> All computers have a place to put numbers–a storage area that can be read from and written to.<span class="intersentencespace"></span>
</li>
<li>Arithmetic logic unit (ALU)
Similarly, to say that a computer “modifies” numbers implies that the computer contains a device for performing operations on numbers.<span class="intersentencespace"></span> This device is the ALU, and it’s the part of the computer that performs arithmetic operations (addition, subtraction, and so on), on numbers from the storage area.<span class="intersentencespace"></span> First, numbers are read from storage into the ALU’s data input port.<span class="intersentencespace"></span> Once inside the ALU, they’re modified by means of an arithmetic calculation, and then they’re written back to storage via the ALU’s output port.
<p>The ALU is actually the green, three-port device at the center of Figure 1-1.<span class="intersentencespace"></span> Note that ALUs aren’t normally understood as having a code input port along with their data input port and results output port.<span class="intersentencespace"></span> They do, of course, have command input lines that let the computer specify which operation the ALU is to carry out on the data arriving at its data input port, so while the depiction of a code input port on the ALU in Figure 1-1 is unique, it is not misleading.<span class="intersentencespace"></span></p>
</li>
<li>Bus
In order to move numbers between the ALU and storage, some means of transmitting numbers is required.<span class="intersentencespace"></span> Thus, the ALU reads from and writes to the data storage area by means of the <em>data bus</em>, which is a network of transmission lines for shuttling numbers around inside the computer.<span class="intersentencespace"></span> Instructions travel into the ALU via the <em>instruction bus</em>, but we won’t cover how instructions arrive at the ALU until Chapter 2.<span class="intersentencespace"></span> For now, the data bus is the only bus that concerns us.<span class="intersentencespace"></span>
</li></ul>
<p>The code stream in <a href="#fig-1-1" class="hyperref">Figure <span class="ref">1.1</span></a> flows into the ALU in the form of a sequence of arithmetic instructions (add, subtract, multiply, and so on).<span class="intersentencespace"></span> The operands for these instructions make up the data stream, which flows over the data bus from the storage area into the ALU. As the ALU carries out operations on the incoming operands, the results stream flows out of the ALU and back into the storage area via the data bus.<span class="intersentencespace"></span> This process continues until the code stream stops coming into the ALU. <a href="#fig-1-3" class="hyperref">Figure <span class="ref">1.3</span></a> expands on <a href="#fig-1-1" class="hyperref">Figure <span class="ref">1.1</span></a> and shows the storage area.</p>
<p>The data enters the ALU from a special storage area, but where does the code stream come from?<span class="intersentencespace"></span> One might imagine that it comes from the keypad of some person standing at the computer and entering a sequence of instructions, each of which is then transmitted to the code input port of the ALU, or perhaps that the code stream is a prerecorded list of instructions that is fed into the ALU, one instruction at a time, by some manual or automated mechanism.<span class="intersentencespace"></span> <a href="#fig-1-3" class="hyperref">Figure <span class="ref">1.3</span></a> depicts the code stream as a prerecorded list of instructions that is stored in a special storage area just like the data stream, and modern computers do store the code stream in just such a manner.</p>
<div class="center figure" id="fig-1-3" data-tralics-id="uid10" data-number="1.3">
<div class="graphics image"><img src="images/figure_1-3.png" alt="images/figure_1-3" /></div><div class="caption"><span class="header">Figure 1.3: </span><span class="description">A simple computer, with an ALU and a region for storing instructions and data.
</span></div></div>
<div class="aside" id="aside-note_1-3" data-tralics-id="uid11" data-number="1.4"><div class="heading"><span class="number">Box 1.4.</span> 
</div>
<p class="noindent">More advanced readers might notice that in <a href="#fig-1-3" class="hyperref">Figure <span class="ref">1.3</span></a> (and in <a href="#fig-1-4" class="hyperref">Figure <span class="ref">1.4</span></a> later) I’ve separated the code and data in main memory after the manner of a Harvard architecture level-one cache.<span class="intersentencespace"></span> In reality, blocks of code and data are mixed together in main memory, but for now I’ve chosen to illustrate them as logically separated.</p>

</div><p>The modern computer’s ability to store and reuse prerecorded sequences of commands makes it fundamentally different from the simpler calculating machines that preceded it.<span class="intersentencespace"></span> Prior to the invention of the first <em>stored-program computer</em>,:<sup id="cha-1_footnote-ref-1" class="footnote"><a href="#cha-1_footnote-1">1</a></sup> all computing devices, from the abacus to the earliest electronic computing machines, had to be manipulated by an operator or group of operators who manually entered a particular sequence of commands each time they wanted to make a particular calculation.<span class="intersentencespace"></span> In contrast, modern computers store and reuse such command sequences, and as such they have a level of flexibility and usefulness that sets them apart from everything that has come before.<span class="intersentencespace"></span> In the rest of this chapter, you’ll get a first-hand look at the many ways that the stored-program concept affects the design and capabilities of the modern computer.</p>
</div>
<div id="uid13" data-tralics-id="uid13" class="subsection" data-number="1.2.2"><h3><a href="#uid13" class="heading hyperref"><span class="number">1.2.2 </span>Refining the File-Clerk Model</a></h3>
<p>Let’s take a closer look at the relationship between the code, data, and results streams by means of a quick example.<span class="intersentencespace"></span> In this example, the code stream consists of a single instruction, an add, which tells the ALU to add two numbers together.</p>
<p>The add instruction travels from code storage to the ALU. For now, let’s not concern ourselves with how the instruction gets from code storage to the ALU; let’s just assume that it shows up at the ALU’s code input port announcing that there is an addition to be carried out immediately.<span class="intersentencespace"></span> The ALU goes through the following sequence of steps:</p>
<ol>
<li>Obtain the two numbers to be added (the input operands) from data storage.<span class="intersentencespace"></span>
</li>
<li>Add the numbers.<span class="intersentencespace"></span>
</li>
<li>Place the results back into data storage.<span class="intersentencespace"></span>
</li></ol>
<p>The preceding example probably sounds simple, but it conveys the basic
manner in which computers–<em>all</em> computers–operate.<span class="intersentencespace"></span> Computers are fed
a sequence of instructions one by one, and in order to execute them, the computer must first obtain the necessary data, then perform the calculation specified by the instruction, and finally write the result into a place where the end user can find it.<span class="intersentencespace"></span> Those three steps are carried out billions of times per second on a modern CPU, again and again and again.<span class="intersentencespace"></span> It’s only because the computer executes these steps so rapidly that it’s able to present the illusion that something much more conceptually complex is going on.</p>
<p>To return to our file-clerk analogy, a computer is like a file clerk who sits at his desk all day waiting for messages from his boss.<span class="intersentencespace"></span> Eventually, the boss sends him a message telling him to perform a calculation on a pair of numbers.<span class="intersentencespace"></span> The message tells him which calculation to perform, and where in his personal filing cabinet the necessary numbers are located.<span class="intersentencespace"></span> So the clerk first retrieves the numbers from his filing cabinet, then performs the calculation, and finally places the results back into the filing cabinet.<span class="intersentencespace"></span> It’s a boring, mindless task that’s repeated endlessly, day in and day out, which is precisely why we’ve invented a machine that can do it efficiently and not complain.</p>
</div></div>
<div id="cid4" data-tralics-id="cid4" class="section" data-number="1.3"><h2><a href="#cid4" class="heading hyperref"><span class="number">1.3 </span>The Register File</a></h2>
<p>Since numbers must first be fetched from storage before they can be added, we want our data storage space to be as fast as possible so that the operation can be carried out quickly.<span class="intersentencespace"></span> Since the ALU is the part of the processor that does the actual addition, we’d like to place the data storage as close as possible to the ALU so it can read the operands almost instantaneously.<span class="intersentencespace"></span> However, practical considerations, such as a CPU’s limited surface area, constrain the size of the storage area that we can stick next to the ALU. This means that in real life, most computers have a relatively small number of very fast data storage locations attached to the ALU. These storage locations are called <em>registers</em>, and the first x86 computers only had eight of them to work with.<span class="intersentencespace"></span> These registers, which are arrayed in a storage structure called a <em>register file</em>, store only a small subset of the data that the code stream needs (and we’ll talk about where the rest of that data lives shortly).</p>
<p>Building on our previous, three-step description of what goes on when a computer’s ALU is commanded to add two numbers, we can modify it as follows.<span class="intersentencespace"></span> To execute an <code>add</code> instruction, the ALU must perform these steps:</p>
<ol>
<li>Obtain the two numbers to be added (the <em>input operands</em>) from two <em>source registers</em>.<span class="intersentencespace"></span>
</li>
<li>Add the numbers.<span class="intersentencespace"></span>
</li>
<li>Place the results back in a <em>destination register</em>.<span class="intersentencespace"></span>
</li></ol>
<p>For a concrete example, let’s look at addition on a simple computer
with only four registers, named <code>A</code>, <code>B</code>, <code>C</code>, and <code>D</code>.<span class="intersentencespace"></span> Suppose each of these registers contains a number, and we want to add the contents of two registers together and overwrite the contents of a third register with the resulting sum, as in the following operation:</p>
<div class="code"><div class="highlight"><pre><span class="n">A</span> <span class="o">+</span> <span class="n">B</span> <span class="o">=</span> <span class="n">C</span> <span class="c1"># Add the contents of registers A and B, and place the result in C,</span>
          <span class="c1"># overwriting whatever was there.</span>
</pre></div></div>
<p>Upon receiving an instruction commanding it to perform this addition operation, the ALU in our simple computer would carry out the following three familiar steps:
1.<span class="intersentencespace"></span> Read the contents of registers <code>A</code> and <code>B</code>.<span class="intersentencespace"></span> 2.<span class="intersentencespace"></span> Add the contents of <code>A</code> and <code>B</code>.<span class="intersentencespace"></span> 3.<span class="intersentencespace"></span> Write the result to register <code>C</code>.</p>
<div class="aside" id="aside-note_1-4" data-tralics-id="uid20" data-number="1.5"><div class="heading"><span class="number">Box 1.5.</span> 
</div>
<p class="noindent">You should recognize these three steps as a more specific form of the read-modify-write sequence from earlier, where the generic modify step is replaced with an addition operation.</p>

</div><p>This three-step sequence is quite simple, but it’s at the very core of how a microprocessor really works.<span class="intersentencespace"></span> In fact, if you glance ahead to <a href="#cha-arm_3" class="hyperref">Chapter <span class="ref">2.5</span></a>’s discussion of the TKTK’s pipeline, you’ll see that it actually has separate stages for each of these three operations: stage TK is the register read step, stage TK is the actual execute step, and stage TK is the write-back step.<span class="intersentencespace"></span> (Don’t worry if you don’t know what a <em>pipeline</em> is, because that’s a topic for <a href="#cha-pipelined_execution" class="hyperref">Chapter <span class="ref">2.5</span></a>.)<span class="intersentencespace"></span> So the TKTK’s ALU reads two operands from the register file, adds them together, and writes the sum back to the register file.<span class="intersentencespace"></span> If we were to stop our discussion right here, you’d already understand the three core stages of the TKTK’s main integer pipeline–all the other stages are either just preparation to get to this point or they’re cleanup work after it.</p>
</div>
<div id="cid5" data-tralics-id="cid5" class="section" data-number="1.4"><h2><a href="#cid5" class="heading hyperref"><span class="number">1.4 </span>RAM: When the Registers Alone Don’t Cut It</a></h2>
<p>Obviously, four (or even eight) registers aren’t even close to the theoretically infinite storage space I mentioned earlier in this chapter.<span class="intersentencespace"></span> In order to make a viable computer that does useful work, you need to be able to store very large
data sets.<span class="intersentencespace"></span> This is where the computer’s <em>main memory</em> comes in.<span class="intersentencespace"></span> Main memory, which in modern computers is always some type of <em>random access memory</em> (RAM), stores the data set on which the computer operates, and only a small portion of that data set at a time is moved to the registers for easy access from the ALU (as shown in <a href="#fig-1-4" class="hyperref">Figure <span class="ref">1.4</span></a>).</p>
<div class="center figure" id="fig-1-4" data-tralics-id="uid21" data-number="1.4">
<div class="graphics image"><img src="images/figure_1-4.png" alt="images/figure_1-4" /></div><div class="caption"><span class="header">Figure 1.4: </span><span class="description">A computer with a register file
</span></div></div>
<p><a href="#fig-1-4" class="hyperref">Figure <span class="ref">1.4</span></a> gives only the slightest indication of it, but main memory is situated quite a bit farther away from the ALU than are the registers.<span class="intersentencespace"></span> In fact, the ALU and the registers are internal parts of the microprocessor, but main memory is a completely separate component of the computer system that is connected to the processor via the <em>memory bus</em>.<span class="intersentencespace"></span> Transferring data between main memory and the registers via the memory bus takes a significant amount of time.<span class="intersentencespace"></span> Thus, if there were no registers and the ALU had to read data directly from main memory for each calculation, computers would run very slowly.<span class="intersentencespace"></span> However, because the registers enable the computer to store data near the ALU, where it can be accessed nearly instantaneously, the computer’s computational speed is decoupled somewhat from the speed of main memory.<span class="intersentencespace"></span> (We’ll discuss the problem of memory access speeds and computational performance in more detail in <a href="#cha-understanding_caching_and_performance" class="hyperref">Chapter <span class="ref">2.5</span></a>, when we talk about caches.)</p>
<div id="uid22" data-tralics-id="uid22" class="subsection" data-number="1.4.1"><h3><a href="#uid22" class="heading hyperref"><span class="number">1.4.1 </span>The File-Clerk Model Revisited and Expanded</a></h3>
<p>To return to our file-clerk metaphor, we can think of main memory as a document storage room located on another floor and the registers as a small, personal filing cabinet where the file clerk places the papers on which he’s currently working.<span class="intersentencespace"></span> The clerk doesn’t really know anything about the document storage room—what it is or where it’s located—because his desk and his personal filing cabinet are all he concerns himself with.<span class="intersentencespace"></span> For documents that are in the storage room, there’s another office worker, the office secretary, whose job it is to locate files in the storage room and retrieve them for the clerk.</p>
<p>This secretary represents a few different units within the processor, all of which we’ll meet <a href="#cha-superscalar_execution" class="hyperref">Chapter <span class="ref">2.5</span></a>.<span class="intersentencespace"></span> For now, suffice it to say that when the boss wants the clerk to work on a file that’s not in the clerk’s personal filing cabinet, the secretary must first be ordered, via a message from the boss, to retrieve the file from the storage room and place it in the clerk’s cabinet so that the clerk can access it when he gets the order to begin working on it.</p>
</div>
<div id="uid23" data-tralics-id="uid23" class="subsection" data-number="1.4.2"><h3><a href="#uid23" class="heading hyperref"><span class="number">1.4.2 </span>An Example: Adding Two Numbers</a></h3>
<p>To translate this office example into computing terms, let’s look at how the computer uses main memory, the register file, and the ALU to add two numbers.<span class="intersentencespace"></span> To add two numbers stored in main memory, the computer must perform these steps:</p>
<ol>
<li>Load the two operands from main memory into the two source registers.<span class="intersentencespace"></span>
</li>
<li>Add the contents of the source registers and place the results in the destination register, using the ALU. To do so, the ALU must perform these steps:
<ul>
<li>Read the contents of registers A and B into the ALU’s input ports.<span class="intersentencespace"></span>
</li>
<li>Add the contents of A and B in the ALU.
</li>
<li>Write the result to register C via the ALU’s output port.<span class="intersentencespace"></span>
</li></ul>
</li>
<li>Store the contents of the destination register in main memory.<span class="intersentencespace"></span>
</li></ol>
<p>Since steps 2a, 2b, and 2c all take a trivial amount of time to complete,
relative to steps 1 and 3, we can ignore them.<span class="intersentencespace"></span> Hence our addition looks like this:</p>
<ol>
<li>Load the two operands from main memory into the two source registers.<span class="intersentencespace"></span>
</li>
<li>Add the contents of the source registers, and place the results in the des- tination register, using the ALU.
</li>
<li>Store the contents of the destination register in main memory.<span class="intersentencespace"></span>
</li></ol>
<p>The existence of main memory means that the user—the boss in our
filing-clerk analogy—must manage the flow of information between main memory and the CPU’s registers.<span class="intersentencespace"></span> This means that the user must issue instructions to more than just the processor’s ALU; he or she must also issue instructions to the parts of the CPU that handle memory traffic.<span class="intersentencespace"></span> Thus, the preceding three steps are representative of the kinds of instruc- tions you find when you take a close look at the code stream.</p>
</div></div>
<div id="cid6" data-tralics-id="cid6" class="section" data-number="1.5"><h2><a href="#cid6" class="heading hyperref"><span class="number">1.5 </span>A Closer Look at the Code Stream: the Program</a></h2>
<p>At the beginning of this chapter, I defined the code stream as consisting of “an ordered sequence of operations,” and this definition is fine as far as it goes.<span class="intersentencespace"></span> But in order to dig deeper, we need a more detailed picture of what the code stream is and how it works.</p>
<p>The term <em>operations</em> suggests a series of simple arithmetic operations like addition or subtraction, but the code stream consists of more than just arithmetic operations.<span class="intersentencespace"></span> Therefore, it would be better to say that the code stream consists of an ordered sequence of <em>instructions</em>.<span class="intersentencespace"></span> Instructions, generally speaking, are commands that tell the whole computer—not just the ALU, but multiple parts of the machine—exactly what actions to perform.<span class="intersentencespace"></span> As we’ve seen, a computer’s list of potential actions encompasses more than just simple arithmetic operations.</p>
<div id="uid33" data-tralics-id="uid33" class="subsection" data-number="1.5.1"><h3><a href="#uid33" class="heading hyperref"><span class="number">1.5.1 </span>General Instruction Types</a></h3>
<p>Instructions are grouped into ordered lists that, when taken as a whole,
tell the different parts of the computer how to work together to perform a specific task, like grayscaling an image or playing a media file.<span class="intersentencespace"></span> These ordered lists of instructions are called <em>programs</em>, and they consist of a few basic types of instructions.</p>
<p>In modern RISC microprocessors, the act of moving data between memory and the registers is under the explicit control of the code stream, or program.<span class="intersentencespace"></span> So if a programmer wants to add two numbers that are located in main memory and then store the result back in main memory, he or she must write a list of instructions (a program) to tell the computer exactly what to do.<span class="intersentencespace"></span> The program must consist of</p>
<p>􏰀* a load instruction to move the two numbers from memory into the registers
􏰀* an add instruction to tell the ALU to add the two numbers
􏰀* a store instruction to tell the computer to place the result of the addition
back into memory, overwriting whatever was previously there.</p>
<p>These operations fall into two main categories:
#### Arithmetic instructions
These instructions tell the ALU to perform an arithmetic calculation (for example, <code>add</code>, <code>sub</code>, <code>mul</code>, <code>div</code>).<span class="intersentencespace"></span> #### Memory-access instructions
These instructions tell the parts of the processor that deal with main memory to move data from and to main memory (for example, load and store).</p>
<div class="aside" id="aside-note_1-5" data-tralics-id="uid34" data-number="1.6"><div class="heading"><span class="number">Box 1.6.</span> 
</div>
<p class="noindent">We’ll discuss a third type of instruction, the branch instruction, shortly.<span class="intersentencespace"></span> Branch instructions are technically a special type of memory-access instruction, but they access code storage instead of data storage.<span class="intersentencespace"></span> Still, it’s easier to treat branches as a third category of instruction.</p>

</div><p>The <em>arithmetic instruction</em> fits with our calculator metaphor and is the type of instruction most familiar to anyone who’s worked with computers.<span class="intersentencespace"></span> Instructions like integer and floating-point addition, subtraction, multipli- cation, and division all fall under this general category.</p>
<div class="aside" id="aside-note_1-6" data-tralics-id="uid35" data-number="1.7"><div class="heading"><span class="number">Box 1.7.</span> 
</div>
<p class="noindent">In order to simplify the discussion and reduce the number of terms, I’m temporarily including logical operations like AND, OR, NOT, NOR, and so on, under the general heading of arithmetic instructions.<span class="intersentencespace"></span> The difference between arithmetic and logical operations will be introduced in <a href="#cha-the_mechanics_of_program_execution" class="hyperref">Chapter <span class="ref">2</span></a>.</p>

</div><p>The <em>memory-access instruction</em> is just as important as the arithmetic instruction, because without access to main memory’s data storage regions, the computer would have no way to get data into or out of the register file.</p>
<p>To show you how memory-access and arithmetic operations work together within the context of the code stream, the remainder of this chapter will use a series of increasingly detailed examples.<span class="intersentencespace"></span> All of the examples are based on a simple, hypothetical computer, which I’ll call the DLW-1.:<sup id="cha-1_footnote-ref-2" class="footnote"><a href="#cha-1_footnote-2">2</a></sup></p>
</div>
<div id="uid37" data-tralics-id="uid37" class="subsection" data-number="1.5.2"><h3><a href="#uid37" class="heading hyperref"><span class="number">1.5.2 </span>The DLW-1’s Basic Architecture and Instruction Formats</a></h3>
<p>The DLW-1 microprocessor consists of an ALU (along with a few other units that I’ll describe later) attached to four registers, named <code>A</code>, <code>B</code>, <code>C</code>, and <code>D</code> for convenience.<span class="intersentencespace"></span> The DLW-1 is attached to a bank of main memory that’s laid out as a line of 256 memory cells, numbered #0 to #255.<span class="intersentencespace"></span> (The number that identifies an individual memory cell is called an <em>address</em>.)</p>
<div id="uid38" data-tralics-id="uid38" class="subsubsection" data-number="1.5.2.1"><h4><a href="#uid38" class="heading">The DLW-1’s Arithmetic Instruction Format</a></h4>
<p>All of the DLW-1’s arithmetic instructions are in the following instruction format:</p>
<div class="code"><div class="highlight"><pre>instruction source1, source2, destination
</pre></div></div>
<p>There are four parts to this instruction format, each of which is called a <em>field</em>.<span class="intersentencespace"></span> The <em>instruction</em> field specifies the type of operation being performed (for example, an addition, a subtraction, a multiplication, and so on).<span class="intersentencespace"></span> The two <em>source</em> fields tell the computer which registers hold the two numbers being operated on, or the operands.<span class="intersentencespace"></span> Finally, the <em>destination</em> field tells the computer which register to place the result in.</p>
<p>As a quick illustration, an addition instruction that adds the numbers in registers <code>A</code> and <code>B</code> (the two source registers) and places the result in register <code>C</code> (the destination register) would look like this:</p>
<div class="code"><div class="highlight"><pre><span class="n">add</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span> <span class="c1"># Add the contents of registers A and B and place the result in C,</span>
            <span class="c1"># overwriting whatever was previously there.</span>
</pre></div></div>
</div>
<div id="uid39" data-tralics-id="uid39" class="subsubsection" data-number="1.5.2.2"><h4><a href="#uid39" class="heading">The DLW-1’s Memory Instruction Format</a></h4>
<p>In order to get the processor to move two operands from main memory into the source registers so they can be added, you need to tell the processor explicitly that you want to move the data in two specific memory cells to two specific registers.<span class="intersentencespace"></span> This “filing” operation is done via a memory-access instruction called the <code>load</code>.</p>
<p>As its name suggests, the <code>load</code> instruction loads the appropriate data from main memory into the appropriate registers so that the data will be available for subsequent arithmetic instructions.<span class="intersentencespace"></span> The <code>store</code> instruction is the reverse of the load instruction, and it takes data from a register and stores it in a location in main memory, overwriting whatever was there previously.</p>
<p>All of the memory-access instructions for the DLW-1 have the following instruction format:</p>
<div class="code"><div class="highlight"><pre>instruction source, destination
</pre></div></div>
<p>For all memory accesses, the instruction field specifies the type of memory operation to be performed (either a <code>load</code> or a <code>store</code>).<span class="intersentencespace"></span> In the case of a <code>load</code>, the source field tells the computer which memory address to fetch the data from, while the destination field specifies which register to put it in.<span class="intersentencespace"></span> Conversely, in the case of a <code>store</code>, the source field tells the computer which register to take the data from, and the destination field specifies which memory address to write the data to.</p>
</div>
<div id="uid40" data-tralics-id="uid40" class="subsubsection" data-number="1.5.2.3"><h4><a href="#uid40" class="heading">An Example DLW-1 Program</a></h4>
<p>Now consider <a href="#code-program-1-1" class="hyperref">Listing <span class="ref">1.1</span></a>, which is a piece of DLW-1 code.<span class="intersentencespace"></span> Each of the lines in the program must be executed in sequence to achieve the desired result.</p>
<div class="codelisting" id="code-program-1-1" data-tralics-id="uid41" data-number="1.1"><div class="heading"><span class="number">Listing 1.1:</span> 

<span class="description">Program to add two numbers from main memory</span>
</div>

<div class="code"><div class="highlight"><pre>load #12, A       //Read the contents of memory cell #12 into register A.
load #13, B       //Read the contents of memory cell #13 into register B.
add A, B, C       //Add the numbers in registers A and B and store the result in C.
store C, #14      //Write the result of the addition from register C into memory cell #14.
</pre></div></div></div><p>Suppose the main memory looked like the following before running <a href="#code-program-1-1" class="hyperref">Listing <span class="ref">1.1</span></a>:</p>
<table class="tabular"><tr class="top_border bottom_border"><td class="left_border align_left right_border">#11</td>
<td class="align_left right_border">#12</td>
<td class="align_left right_border">#13</td>
<td class="align_left right_border">#14</td>
</tr><tr class="bottom_border"><td class="left_border align_left right_border">12</td>
<td class="align_left right_border">6</td>
<td class="align_left right_border">2</td>
<td class="align_left right_border">3</td>
</tr></table>
<p>After doing our addition and storing the results, the memory would be changed so that the contents of cell #14 would be overwritten by the sum of cells #12 and #13, as shown here:</p>
<table class="tabular"><tr class="top_border bottom_border"><td class="left_border align_left right_border">#11</td>
<td class="align_left right_border">#12</td>
<td class="align_left right_border">#13</td>
<td class="align_left right_border">#14</td>
</tr><tr class="bottom_border"><td class="left_border align_left right_border">12</td>
<td class="align_left right_border">6</td>
<td class="align_left right_border">2</td>
<td class="align_left right_border">8</td>
</tr></table>
</div></div></div>
<div id="cid7" data-tralics-id="cid7" class="section" data-number="1.6"><h2><a href="#cid7" class="heading hyperref"><span class="number">1.6 </span>A Closer Look at Memory Accesses: Register vs.<span class="intersentencespace"></span> Immediate</a></h2>
<p>The examples so far presume that the programmer knows the exact memory location of every number that he or she wants to load and store.<span class="intersentencespace"></span> In other words, it presumes that in composing each program, the programmer has at his or her disposal a list of the contents of memory cells #0 through #255.</p>
<p>While such an accurate snapshot of the initial state of main memory may be feasible for a small example computer with only 256 memory locations, such snapshots almost never exist in the real world.<span class="intersentencespace"></span> Real computers have billions of possible locations in which data can be stored, so programmers need a more flexible way to access memory, a way that doesn’t require each memory access to specify numerically an exact memory address.</p>
<p>Modern computers allow the <em>contents</em> of a register to be used as a memory address, a move that provides the programmer with the desired flexibility.<span class="intersentencespace"></span> But before discussing the effects of this move in more detail, let’s take one more look at the basic add instruction.</p>
<div id="uid42" data-tralics-id="uid42" class="subsection" data-number="1.6.1"><h3><a href="#uid42" class="heading hyperref"><span class="number">1.6.1 </span>Immediate Values</a></h3>
<p>All of the arithmetic instructions so far have required two source registers as input.<span class="intersentencespace"></span> However, it’s possible to replace one or both of the source registers with an explicit numerical value, called an <em>immediate value</em>.<span class="intersentencespace"></span> For instance, to increase whatever number is in register A by 2, we don’t need to load the value 2 into a second source register, like B, from some cell in main memory that contains that value.<span class="intersentencespace"></span> Rather, we can just tell the computer to add 2 to A directly, as follows:</p>
<div class="code"><div class="highlight"><pre>add A, 2, A  //Add 2 to the contents of register A and place the result back into A, overwriting whatever was there.
</pre></div></div>
<p>I’ve actually been using immediate values all along in my examples, but just not in any arithmetic instructions.<span class="intersentencespace"></span> In all of the preceding examples, each load and store uses an immediate value in order to specify a memory address.<span class="intersentencespace"></span> So the #12 in the load instruction in line 1 of <a href="#code-program-1-1" class="hyperref">Listing <span class="ref">1.1</span></a> is just an immediate value (a regular whole number) prefixed by a # sign to let the computer know that this particular immediate value is a memory address that designates a cell in memory.</p>
<p>Memory addresses are just regular whole numbers that are specially marked with the # sign.<span class="intersentencespace"></span> Because they’re regular whole numbers, they can be stored in registers—and stored in memory—just like any other number.<span class="intersentencespace"></span> Thus, the whole-number contents of a register, like <code>D</code>, could be construed by the computer as representing a memory address.</p>
<p>For example, say that we’ve stored the number 12 in register <code>D</code>, and that we intend to use the contents of <code>D</code> as the address of a memory cell in <a href="#code-program-1-2" class="hyperref">Listing <span class="ref">1.2</span></a>.</p>
<div class="codelisting" id="code-program-1-2" data-tralics-id="uid43" data-number="1.2"><div class="heading"><span class="number">Listing 1.2:</span> 

<span class="description">Program to add two numbers from main memory using an address stored in a register</span>
</div>

<div class="code"><div class="highlight"><pre>load #D, A   //Read the contents of the memory cell designated by the number stored in D (where D = 12) into register A.
load #13, B  //Read the contents of memory cell #13 into register B.
add A, B, C  //Add the numbers in registers A and B and store the result in C.
store C, #14 //Write the result of the addition from register C into memory cell #14.
</pre></div></div></div><p>Program 1-2 is essentially the same as Program 1-1, and given the same input, it yields the same results.<span class="intersentencespace"></span> The only difference is in line 1.</p>
<p><a href="#code-program-1-1" class="hyperref">Listing <span class="ref">1.1</span></a>, Line 1
<code>load #12, A</code></p>
<p><a href="#code-program-1-2" class="hyperref">Listing <span class="ref">1.2</span></a>, Line 1
<code>load #D, A</code></p>
<p>Since the content of <code>D</code> is the number 12, we can tell the computer to look in <code>D</code> for the memory cell address by substituting the register name (this time marked with a # sign for use as an address), for the actual memory cell number in line 1’s <code>load</code> instruction.<span class="intersentencespace"></span> Thus, the first lines of <a href="#code-program-1-1" class="hyperref">Listing <span class="ref">1.1</span></a> and <a href="#code-program-1-2" class="hyperref">Listing <span class="ref">1.2</span></a> are functionally equivalent.</p>
<p>This same trick works for store instructions, as well.<span class="intersentencespace"></span> For example, if we place the number 14 in <code>D</code> we can modify the store command in line 4 of <a href="#code-program-1-1" class="hyperref">Listing <span class="ref">1.1</span></a> to read as follows: <code>store C, #D</code>.<span class="intersentencespace"></span> Again, this modification would not change the program’s output.</p>
<p>Because memory addresses are just regular numbers, they can be stored in memory cells as well as in registers.<span class="intersentencespace"></span> <a href="#code-program-1-3" class="hyperref">Listing <span class="ref">1.3</span></a> illustrates the use of a memory address that’s stored in another memory cell.<span class="intersentencespace"></span> If we take the input for <a href="#code-program-1-1" class="hyperref">Listing <span class="ref">1.1</span></a> and apply it to <a href="#code-program-1-3" class="hyperref">Listing <span class="ref">1.3</span></a>, we get the same output as if we’d just run <a href="#code-program-1-1" class="hyperref">Listing <span class="ref">1.1</span></a> without modification:</p>
<div class="codelisting" id="code-program-1-3" data-tralics-id="uid44" data-number="1.3"><div class="heading"><span class="number">Listing 1.3:</span> 

<span class="description">Program to add two numbers from memory using an address stored in a memory cell.</span>
</div>

<div class="code"><div class="highlight"><pre>load #11, D  //Read the contents of memory cell #11 into D.
load #D, A   //Read the contents of the memory cell designated by the number in D (where D = 12) into register A.
load #13, B  //Read the contents of memory cell #13 into register B.
add A, B, C  //Add the numbers in registers A and B and store the result in C.
store C, #14 //Write the result of the addition from register C into memory cell #14.
</pre></div></div></div><p>The first instruction in <a href="#code-program-1-3" class="hyperref">Listing <span class="ref">1.3</span></a> loads the number 12 from memory cell #11 into register <code>D</code>.<span class="intersentencespace"></span> The second instruction then uses the content of <code>D</code> (which is the value 12) as a memory address in order to load register <code>A</code> into memory location #12.</p>
<p>But why go to the trouble of storing memory addresses in memory cells and then loading the addresses from main memory into the registers before they’re finally ready to be used to access memory again?<span class="intersentencespace"></span> Isn’t this an overly complicated way to do things?</p>
<p>Actually, these capabilities are designed to make programmers’ lives easier, because when used with the register-relative addressing technique described next they make managing code and data traffic between the processor and massive amounts of main memory much less complex.</p>
</div>
<div id="uid45" data-tralics-id="uid45" class="subsection" data-number="1.6.2"><h3><a href="#uid45" class="heading hyperref"><span class="number">1.6.2 </span>Register-Relative Addressing</a></h3>
<p>In real-world programs, loads and stores most often use <em>register-relative</em> addressing, which is a way of specifying memory addresses relative to a register that contains a fixed <em>base address</em>.</p>
<p>For example, we’ve been using <code>D</code> to store memory addresses, so let’s say that on the DLW-1 we can assume that, unless it is explicitly told to do otherwise, the operating system always loads the starting address (or base address) of a program’s <em>data segment</em> into <code>D</code>.<span class="intersentencespace"></span> Remember that code and data are logically separated in main memory, and that data flows into the processor from a data storage area, while code flows into the processor from a special code storage area.<span class="intersentencespace"></span> Main memory itself is just one long row of undifferentiated memory cells, each one <em>byte</em> in width, that store numbers.<span class="intersentencespace"></span> The computer carves up this long row of bytes into multiple segments, some of which store code and some of which store data.</p>
<p>A <em>data segment</em> is a block of contiguous memory cells that a program stores all of its data in, so if a programmer knows a data segment’s starting address (<em>base address</em>) in memory, he or she can access all of the other memory locations in that segment using this formula:
</p><div class="code"><div class="highlight"><pre>base address + offset
</pre></div></div>
<p>where offset is the distance in bytes of the desired memory location from the data segment’s base address.</p>
<p>Thus, <code>load</code> and <code>store</code> instructions in DLW-1 assembly would normally look something like this:</p>
<div class="code"><div class="highlight"><pre>load #(D + 108), A   //Read the contents of the memory cell at location #(D + 108) into A.
store B, #(D + 108)  //Write the contents of B into the memory cell at location #(D + 108).
</pre></div></div>
<p>In the case of the load, the processor takes the number in D, which is the base address of the data segment, adds 108 to it, and uses the result as the load’s destination memory address.<span class="intersentencespace"></span> The store works in the exact same way.</p>
<p>Of course, this technique requires that a quick addition operation (called an <em>address calculation</em>) be part of the execution of the load instruction, so this is why the <em>load-store units</em> on modern processors contain very fast integer addition hardware.<span class="intersentencespace"></span> (As we’ll learn in Chapter 4, the load-store unit is the <em>execution unit</em> responsible for executing <code>load</code> and <code>store</code> instructions, just like the <em>arithmetic-logic unit</em> is responsible for executing arithmetic instructions.)</p>
<p>By using register-relative addressing instead of <em>absolute addressing</em> (in which memory addresses are given as immediate values), a programmer can write programs without knowing the exact location of data in memory.<span class="intersentencespace"></span> All the programmer needs to know is which register the operating system will place the data segment’s base address in, and he or she can do all memory accesses relative to that base address.<span class="intersentencespace"></span> In situations where a programmer uses absolute addressing, when the operating system loads the program into memory, all of the program’s immediate address values have to be changed to reflect the data segment’s actual location in memory.</p>
<p>Because both memory addresses and regular integer numbers are stored in the same registers, these registers are called <em>general-purpose registers</em> (GPRs).<span class="intersentencespace"></span> On the DLW-1, A, B, C, and D are all GPRs.</p>
</div></div>
<div id="cha-1_footnotes">
  <ol class="footnotes">
    <li id="cha-1_footnote-1">In 1944 J. Presper Eckert, John Mauchly, and John von Neumann proposed the first stored-program computer, the EDVAC (Electronic Discreet Variable Automatic Computer), and in 1949 such a machine, the EDSAC, was built by Maurice Wilkes of Cambridge University. <a class="arrow" href="#cha-1_footnote-ref-1">↑</a></li>
    <li id="cha-1_footnote-2">“DLW” in honor of the DLX architecture used by Hennessy and Patterson in their books on computer architecture. <a class="arrow" href="#cha-1_footnote-ref-2">↑</a></li>
  </ol>
</div><div id="cha-the_mechanics_of_program_execution" data-tralics-id="cid8" class="chapter" data-number="2"><h1><a href="#cha-the_mechanics_of_program_execution" class="heading hyperref"><span class="number">Chapter 2 </span>The Mechanics of Program Execution</a></h1>
<p>Now that we understand the basics of computer organization, it’s time to take a
closer look at the nuts and bolts of how stored programs are actually executed by the computer.</p>
<p>To that end, this chapter will cover core programming concepts like machine language, the programming model, the instruction set architecture, branch instructions, and the fetch-execute loop.</p>
</div>
<div id="cid9" data-tralics-id="cid9" class="section" data-number="2.1"><h2><a href="#cid9" class="heading hyperref"><span class="number">2.1 </span>Opcodes and Machine Language</a></h2>
<p>If you’ve been following the discussion so far, it shouldn’t surprise you to learn that both memory addresses and instructions are ordinary numbers that can be stored in memory.<span class="intersentencespace"></span> All of the instructions in a program like Program 1-1 are represented inside the computer as strings of numbers.<span class="intersentencespace"></span> Indeed, a program is one long string of numbers stored in a series of memory locations.<span class="intersentencespace"></span> ￼
How is a program like Program 1-1 rendered in numerical notation so that it can be stored in memory and executed by the computer?<span class="intersentencespace"></span> The answer is simpler than you might think.</p>
<p>As you may already know, a computer actually only understands 1s and 0s (or “high” and “low” electric voltages), not English words like <em>add</em>, <em>load</em>, and <em>store</em>, or letters and base-10 numbers like A, B, 12, and 13.<span class="intersentencespace"></span> In order for the computer to run a program, therefore, all of its instructions must be rendered in <em>binary notation</em>.<span class="intersentencespace"></span> Think of translating English words into Morse code’s dots and dashes and you’ll have some idea of what I’m talking about.</p>
<div id="uid46" data-tralics-id="uid46" class="subsection" data-number="2.1.1"><h3><a href="#uid46" class="heading hyperref"><span class="number">2.1.1 </span>Machine Language on the DLW-1</a></h3>
<p>The translation of programs of any complexity into this binary-based <em>machine language</em> is a massive undertaking that’s meant to be done by a computer, but I’ll show you the basics of how it works so you can understand what’s going on.<span class="intersentencespace"></span> The following example is simplified, but useful nonetheless.</p>
<p>The English words in a program, like <em>add</em>, <em>load</em>, and <em>store</em>, are <em>mnemonics</em> (meaning they’re easy for people to remember), and they’re all mapped to strings of binary numbers, called <em>opcodes</em>, that the computer can understand.<span class="intersentencespace"></span> Each opcode designates a different operation that the processor can perform.<span class="intersentencespace"></span> Table 2-1 maps each of the mnemonics used in Chapter 1 to a 3-bit opcode for the hypothetical DLW-1 microprocessor.<span class="intersentencespace"></span> We can also map the four register names to 2-bit binary codes, as shown in Table 2-2.</p>
<table class="tabular"><tr class="top_border bottom_border"><td class="left_border align_left right_border">Mnemonic</td>
<td class="align_left right_border">Opcode</td>
</tr><tr><td class="left_border align_left right_border"><code>add</code></td>
<td class="align_left right_border"><code>000</code></td>
</tr><tr><td class="left_border align_left right_border"><code>sub</code></td>
<td class="align_left right_border"><code>001</code></td>
</tr><tr><td class="left_border align_left right_border"><code>load</code></td>
<td class="align_left right_border"><code>010</code></td>
</tr><tr class="bottom_border"><td class="left_border align_left right_border"><code>store</code></td>
<td class="align_left right_border"><code>011</code></td>
</tr></table>
<p>Table 2-1: Mapping of Mnemonics to Opcodes for the DLW-1</p>
<table class="tabular"><tr class="top_border bottom_border"><td class="left_border align_left right_border">Register</td>
<td class="align_left right_border">Binary Code</td>
</tr><tr><td class="left_border align_left right_border"><code>A</code></td>
<td class="align_left right_border"><code>00</code></td>
</tr><tr><td class="left_border align_left right_border"><code>B</code></td>
<td class="align_left right_border"><code>01</code></td>
</tr><tr><td class="left_border align_left right_border"><code>C</code></td>
<td class="align_left right_border"><code>10</code></td>
</tr><tr class="bottom_border"><td class="left_border align_left right_border"><code>D</code></td>
<td class="align_left right_border"><code>11</code></td>
</tr></table>
<p>Table 2-2: Mapping of Registers to Binary Codes for the DLW-1</p>
<p>The binary values representing both the opcodes and the register codes are arranged in one of a number of 16-bit (or 2-byte) formats to get a complete <em>machine language instruction</em>, which is a binary number that can be stored in RAM and used by the processor.</p>
<div class="aside" id="aside-note_2-1" data-tralics-id="uid47" data-number="2.1"><div class="heading"><span class="number">Box 2.1.</span> 
</div>
<p class="noindent">Because programmer-written instructions must be translated into binary codes before a computer can read them, it is common to see programs in any format—binary, assembly, or a high-level language like BASIC or C, referred to generically as “code” or “codes.” So programmers sometimes speak of “assembler code,” “binary code,” or “C code,” when referring to programs written in assembly, binary, or C language.<span class="intersentencespace"></span> Programmers also will often describe the act of programming as “writing code” or “coding.” I have adopted this terminology in this book, and will henceforth use the term “code” regularly to refer generically to instruction sequences and programs.</p>

</div></div>
<div id="uid48" data-tralics-id="uid48" class="subsection" data-number="2.1.2"><h3><a href="#uid48" class="heading hyperref"><span class="number">2.1.2 </span>Binary Encoding of Arithmetic Instructions</a></h3>
<p>Arithmetic instructions have the simplest machine language instruction formats, so we’ll start with them.<span class="intersentencespace"></span> Figure 2-1 shows the format for the machine language encoding of a register-type arithmetic instruction.</p>
<div class="center figure" id="fig-2-1" data-tralics-id="uid49" data-number="2.1">
<div class="graphics image"><img src="images/figure_2-1.png" alt="images/figure_2-1" /></div><div class="caption"><span class="header">Figure 2.1: </span><span class="description">Machine language format for a register-type instruction
</span></div></div>
<p>In a register-type arithmetic instruction (that is, an arithmetic instruc- tion that uses only registers and no immediate values), the first bit of the instruction is the <em>mode bit</em>.<span class="intersentencespace"></span> If the mode bit is set to 0, then the instruction is a register-type instruction; if it’s set to 1, then the instruction is of the immediate type.</p>
<p>Bits 1–3 of the instruction specify the opcode, which tells the computer what type of operation the instruction represents.<span class="intersentencespace"></span> Bits 4–5 specify the instruc- tion’s first source register, 6–7 specify the second source register, and 8–9 specify the destination register.<span class="intersentencespace"></span> The last six bits are not needed by register-to- register arithmetic instructions, so they’re padded with 0s (they’re <em>zeroed out</em> in computer jargon) and ignored.</p>
<p>Now, let’s use the binary values in Tables 2-1 and 2-2 to translate the add instruction in line 3 of Program 1-1 into a 2-byte (or 16-bit) machine language instruction:</p>
<table class="tabular"><tr class="top_border bottom_border"><td class="left_border align_left right_border">Assembly Language Instruction</td>
<td class="align_left right_border">Machine Language Instruction</td>
</tr><tr><td class="left_border align_left right_border"><code>add A, B, C</code></td>
<td class="align_left right_border"><code>00000001 10000000</code></td>
</tr><tr><td class="left_border align_left right_border"><code>add C, D, A</code></td>
<td class="align_left right_border"><code>00001011 00000000</code></td>
</tr><tr><td class="left_border align_left right_border"><code>add D, B, C</code></td>
<td class="align_left right_border"><code>00001101 10000000</code></td>
</tr><tr class="bottom_border"><td class="left_border align_left right_border"><code>sub A, D, C</code></td>
<td class="align_left right_border"><code>00010011 10000000</code></td>
</tr></table>
<p>Increasing the number of binary digits in the opcode and register fields increases the total number of instructions the machine can use and the number of registers it can have.<span class="intersentencespace"></span> For example, if you know something about binary notation, then you probably know that a 3-bit opcode allows the processor to map up to 23 mnemonics, which means that it can have up to 23, or 8, instructions in its <em>instruction set</em>; increasing the opcode size to 8 bits would allow the processor’s instruction set to contain up to 28, or 256, instructions.<span class="intersentencespace"></span> Similarly, increasing the number of bits in the register field increases the possible number of registers that the machine can have.</p>
<p>Arithmetic instructions containing an immediate value use an immediate- type instruction format, which is slightly different from the register-type format we just saw.<span class="intersentencespace"></span> In an immediate-type instruction, the first byte contains the opcode, the source register, and the destination register, while the second byte contains the immediate value, as shown in Figure 2-2.</p>
<div class="center figure" id="fig-2-2" data-tralics-id="uid50" data-number="2.2">
<div class="graphics image"><img src="images/figure_2-2.png" alt="images/figure_2-2" /></div><div class="caption"><span class="header">Figure 2.2: </span><span class="description">Machine language format for an immediate-type instruction
</span></div></div>
<p>Here are a few immediate-type arithmetic instructions translated from assembly language to machine language:</p>
<table class="tabular"><tr class="top_border bottom_border"><td class="left_border align_left right_border">Assembly Language Instruction</td>
<td class="align_left right_border">Machine Language Instruction</td>
</tr><tr><td class="left_border align_left right_border"><code>add C, 8, A</code></td>
<td class="align_left right_border"><code>10001000 00001000</code></td>
</tr><tr><td class="left_border align_left right_border"><code>add 5, A, C</code></td>
<td class="align_left right_border"><code>10000010 00000101</code></td>
</tr><tr class="bottom_border"><td class="left_border align_left right_border"><code>sub 25, D, C</code></td>
<td class="align_left right_border"><code>10011110 00011001</code></td>
</tr></table>
</div>
<div id="uid51" data-tralics-id="uid51" class="subsection" data-number="2.1.3"><h3><a href="#uid51" class="heading hyperref"><span class="number">2.1.3 </span>Binary Encoding of Memory Access Instructions</a></h3>
<p>Memory-access instructions use both register- and immediate-type instruction formats exactly like those shown for arithmetic instructions.<span class="intersentencespace"></span> The only difference lies in how they use them.<span class="intersentencespace"></span> Let’s take the case of a load first.</p>
<div id="uid52" data-tralics-id="uid52" class="subsubsection" data-number="2.1.3.1"><h4><a href="#uid52" class="heading">The load Instruction</a></h4>
<p>We’ve previously seen two types of <code>load</code>, the first of which was the immediate type.<span class="intersentencespace"></span> An immediate-type <code>load</code> (see Figure 2-3) uses the immediate-type instruction format, but because the <code>load</code>’s source is an immediate value (a memory address) and not a register, the source field is unneeded and must be zeroed out.<span class="intersentencespace"></span> (The source field is not ignored, though, and in a moment we’ll see what happens if it isn’t zeroed out.)</p>
<div class="center figure" id="fig-2-3" data-tralics-id="uid53" data-number="2.3">
<div class="graphics image"><img src="images/figure_2-3.png" alt="images/figure_2-3" /></div><div class="caption"><span class="header">Figure 2.3: </span><span class="description">Machine language format for an immediate-type load
</span></div></div>
<p>Now let’s translate the immediate-type load in line 1 of Program 1-1 (12 is 1100 in binary notation):</p>
<table class="tabular"><tr class="top_border bottom_border"><td class="left_border align_left right_border">Assembly Language Instruction</td>
<td class="align_left right_border">Machine Language Instruction</td>
</tr><tr class="bottom_border"><td class="left_border align_left right_border"><code>load #12, A</code></td>
<td class="align_left right_border"><code>10100000 00001100</code></td>
</tr></table>
<p>The 2-byte machine language instruction on the right is a binary representation of the assembly language instruction on the left.<span class="intersentencespace"></span> The first byte corresponds to an immediate-type <code>load</code> instruction that takes register <code>A</code> as its destination.<span class="intersentencespace"></span> The second byte is the binary representation of the number 12, which is the source address in memory that the data is to be loaded from.</p>
<p>The second type of <code>load</code> we’ve seen is the register type.<span class="intersentencespace"></span> A register-type <code>load</code> uses the register-type instruction format, but with the source2 field zeroed out and ignored, as shown in Figure 2-4.</p>
<p>In Figure 2-4, the source1 field specifies the register containing the memory address that the processor is to load data from, and the destination field specifies the register that the loaded data is to be placed in.</p>
<div class="center figure" id="fig-2-4" data-tralics-id="uid54" data-number="2.4">
<div class="graphics image"><img src="images/figure_2-4.png" alt="images/figure_2-4" /></div><div class="caption"><span class="header">Figure 2.4: </span><span class="description">Machine language format for a register-type load
</span></div></div>
<p>For a register-relative addressed <code>load</code>, we use a version of the immediate-type instruction format, shown in Figure 2-5, with the base field specifying the register that contains the base address and the offset stored in the second byte of the instruction.</p>
<div class="center figure" id="fig-2-5" data-tralics-id="uid55" data-number="2.5">
<div class="graphics image"><img src="images/figure_2-5.png" alt="images/figure_2-5" /></div><div class="caption"><span class="header">Figure 2.5: </span><span class="description">Machine language format for a register-relative load
</span></div></div>
<p>Recall from Table 2-2 that 00 is the binary number that designates register <code>A</code>.<span class="intersentencespace"></span> Therefore, as a result of the DLW-1’s particular machine language encoding scheme, any register but <code>A</code> could theoretically be used to store the base address for a register-relative load.</p>
</div>
<div id="uid56" data-tralics-id="uid56" class="subsubsection" data-number="2.1.3.2"><h4><a href="#uid56" class="heading">The store Instruction</a></h4>
<p>The register-type binary format for a <code>store</code> instruction is the same as it is for a load, except that the destination field specifies a register containing a destination memory address, and the source1 field specifies the register containing the data to be stored to memory.</p>
<p>The immediate-type machine language format for a <code>store</code>, pictured in Figure 2-6, is also similar to the immediate-type format for a <code>load</code>, except that since the destination register is not needed (the destination is the immediate memory address) the destination field is zeroed out, while the source field specifies which register holds the data to be stored.</p>
<div class="center figure" id="fig-2-6" data-tralics-id="uid57" data-number="2.6">
<div class="graphics image"><img src="images/figure_2-6.png" alt="images/figure_2-6" /></div><div class="caption"><span class="header">Figure 2.6: </span><span class="description">Machine language format for an immediate-type store
</span></div></div>
<p>The register-relative <code>store</code>, on the other hand, uses the same immediate-type instruction format used for the register-relative <code>load</code> (Figure 2-5), but the destination field is set to a nonzero value, and the offset is stored in the second byte.<span class="intersentencespace"></span> Again, the base address for a register-relative <code>store</code> can theoretically be stored in any register other than A, although by convention it’s stored in D.</p>
</div></div>
<div id="uid58" data-tralics-id="uid58" class="subsection" data-number="2.1.4"><h3><a href="#uid58" class="heading hyperref"><span class="number">2.1.4 </span>Translating an Example Program into Machine Language</a></h3>
<p>For our simple computer with four registers, three instructions, and 256 memory cells, it’s tedious but trivial to translate Program 1-1 into machine- readable binary representation using the previous tables and instruction formats.<span class="intersentencespace"></span> Program 2-1 shows the translation.</p>
<table class="tabular"><tr class="top_border bottom_border"><td class="left_border align_left right_border">Assembly Language</td>
<td class="align_left right_border">Machine Language</td>
</tr><tr><td class="left_border align_left right_border"><code>load #12, A</code></td>
<td class="align_left right_border"><code>10100000 00001100</code></td>
</tr><tr><td class="left_border align_left right_border"><code>load #13, B</code></td>
<td class="align_left right_border"><code>10100001 00001101</code></td>
</tr><tr><td class="left_border align_left right_border"><code>add A, B, C</code></td>
<td class="align_left right_border"><code>00000001 10000000</code></td>
</tr><tr class="bottom_border"><td class="left_border align_left right_border"><code>store C, #14</code></td>
<td class="align_left right_border"><code>10111000 00001110</code></td>
</tr></table>
<p>Program 2-1: A translation of Program 1-1 into machine language</p>
<p>The 1s and 0s in the rightmost column of Program 2-1 represent the high and low voltages that the computer “thinks” in.</p>
<p>Real machine language instructions are usually longer and more complex than the simple ones I’ve given here, but the basic idea is exactly the same.<span class="intersentencespace"></span> Program instructions are translated into machine language in a mechanical, predefined manner, and even in the case of a fully modern microprocessor, doing such translations by hand is merely a matter of knowing the instruction formats and having access to the right charts and tables.</p>
<p>Of course, for the most part the only people who do such translations by hand are computer engineering or computer science undergraduates who’ve been assigned them for homework.<span class="intersentencespace"></span> This wasn’t always the case, though.</p>
</div></div>
<div id="cid10" data-tralics-id="cid10" class="section" data-number="2.2"><h2><a href="#cid10" class="heading hyperref"><span class="number">2.2 </span>The Programming Model and the ISA</a></h2>
<p>Back in the bad old days, programmers had to enter programs into the computer directly in machine language (after having walked five miles in the snow uphill to work).<span class="intersentencespace"></span> In the very early stages of computing, this was done by flipping switches.<span class="intersentencespace"></span> The programmer toggled strings of 1s and 0s into the computer’s very limited memory, ran the program, and then pored over the resulting strings of 1s and 0s to decode the answer.</p>
<p>Once memory sizes and processing power increased to the point where programmer time and effort were valuable enough relative to computing time and memory space, computer scientists devised ways of allowing the computer to use a portion of its power and memory to take on some of the burden of making its cryptic input and output a little more human-friendly.</p>
<p>In short, the tedious task of converting human-readable programs into machine-readable binary code was automated; hence the birth of assembly language programming.<span class="intersentencespace"></span> Programs could now be written using mnemonics, register names, and memory locations, before being converted by an assembler into machine language for processing.</p>
<p>In order to write assembly language programs for a machine, you have to understand the machine’s available resources: how many registers it has, what instructions it supports, and so on.<span class="intersentencespace"></span> In other words, you need a well-defined model of the machine you’re trying to program.</p>
<div id="uid59" data-tralics-id="uid59" class="subsection" data-number="2.2.1"><h3><a href="#uid59" class="heading hyperref"><span class="number">2.2.1 </span>The Programming Model</a></h3>
<p>The <em>programming model</em> is the programmer’s interface to the microprocessor.<span class="intersentencespace"></span> It hides all of the processor’s complex implementation details behind a relatively simple, clean layer of abstraction that exposes to the programmer all of the processor’s functionality.<span class="intersentencespace"></span> (See Chapter 4 for more on the history and development of the programming model.)</p>
<p>Figure 2-7 shows a diagram of a programming model for an eight-register machine.<span class="intersentencespace"></span> By now, most of the parts of the diagram should be familiar to you.<span class="intersentencespace"></span> The ALU performs arithmetic, the registers store numbers, and the <em>input-output unit</em> (I/O unit) is responsible for interacting with memory and the rest of the system (via loads and stores).<span class="intersentencespace"></span> The parts of the processor that we haven’t yet met lie in the <em>control unit</em>.<span class="intersentencespace"></span> Of these, we’ll cover the <em>program counter</em> and the <em>instruction register</em> now.</p>
</div>
<div id="uid60" data-tralics-id="uid60" class="subsection" data-number="2.2.2"><h3><a href="#uid60" class="heading hyperref"><span class="number">2.2.2 </span>The Instruction Register and Program Counter</a></h3>
<p>Because programs are stored in memory as ordered sequences of instruc- tions and memory is arranged as a linear series of addresses, each instruction in a program lives at its own memory address.<span class="intersentencespace"></span> In order to step through and execute the lines of a program, the computer simply begins at the program’s starting address and then steps through each successive memory location, fetching each successive instruction from memory, placing it in a special register, and executing it as shown in Figure 2-8.</p>
<div class="center figure" id="fig-2-7" data-tralics-id="uid61" data-number="2.7">
<div class="graphics image"><img src="images/figure_2-7.png" alt="images/figure_2-7" /></div><div class="caption"><span class="header">Figure 2.7: </span><span class="description">The programming model for a simple eight-register machine
</span></div></div>
<p>The instructions in our DLW-1 computer are two bytes long.<span class="intersentencespace"></span> If we assume that each memory cell holds one byte, then the DLW-1 must step through memory by fetching instructions from two cells at a time.</p>
<div class="center figure" id="fig-2-8" data-tralics-id="uid62" data-number="2.8">
<div class="graphics image"><img src="images/figure_2-8.png" alt="images/figure_2-8" /></div><div class="caption"><span class="header">Figure 2.8: </span><span class="description">A simple computer with instruction and data registers
</span></div></div>
<p>For example, if the starting address in Program 1-1 were #500, it would look like Figure 2-9 in memory (with the instructions rendered in machine language, not assembly language, of course).</p>
<div class="center figure" id="fig-2-9" data-tralics-id="uid63" data-number="2.9">
<div class="graphics image"><img src="images/figure_2-9.png" alt="images/figure_2-9" /></div><div class="caption"><span class="header">Figure 2.9: </span><span class="description">An illustration of Program 1-1 in memory, starting at address #500
</span></div></div>
</div>
<div id="uid64" data-tralics-id="uid64" class="subsection" data-number="2.2.3"><h3><a href="#uid64" class="heading hyperref"><span class="number">2.2.3 </span>The Instruction Fetch: Loading the Instruction Register</a></h3>
<p>An <em>instruction fetch</em> is a special type of load that happens automatically for every instruction.<span class="intersentencespace"></span> It always takes the address that’s currently in the program counter register as its source and the <em>instruction register</em> as its destination.<span class="intersentencespace"></span> The control unit uses a fetch to load each instruction of a program from memory into the instruction register, where that instruction is <em>decoded</em> before being executed; and while that instruction is being decoded, the processor places the address of the next instruction into the program counter by incrementing the address that’s currently in the program counter, so that the newly incremented address points to the next instruction the sequence.<span class="intersentencespace"></span> In the case of our DLW-1, the program counter is incremented by two every time an instruction is fetched, because the two-byte instructions begin at every other byte in memory.</p>
</div>
<div id="uid65" data-tralics-id="uid65" class="subsection" data-number="2.2.4"><h3><a href="#uid65" class="heading hyperref"><span class="number">2.2.4 </span>Running a Simple Program: the Fetch-Execute Loop</a></h3>
<p>In Chapter 1 we discussed the steps a processor takes to perform calculations on numbers using the ALU in combination with a fetched arithmetic instruc- tion.<span class="intersentencespace"></span> Now let’s look at the steps the processor takes in order to fetch a series of instructions—a program—and feed them to either the ALU (in the case of arithmetic instructions) or the memory access hardware (in the case of loads and stores):</p>
<ol>
<li><em>Fetch</em> the next instruction from the address stored in the program counter, and load that instruction into the instruction register.<span class="intersentencespace"></span> Increment the program counter.<span class="intersentencespace"></span>
</li>
<li><em>Decode</em> the instruction in the instruction register.<span class="intersentencespace"></span>
</li>
<li><em>Execute</em> the instruction in the instruction register, using the following
rules:
<ul>
<li>If the instruction is an arithmetic instruction, execute it using the ALU and register file.<span class="intersentencespace"></span>
</li>
<li>If the instruction is a memory access instruction, execute it using the memory-access hardware.<span class="intersentencespace"></span>
</li></ul>
<p>These three steps are fairly straightforward, and with one modification
they describe the way that microprocessors execute programs (as we’ll see in the section “Branch Instructions” on page 30).<span class="intersentencespace"></span> Computer scientists often refer to these steps as the <em>fetch-execute loop</em> or the <em>fetch-execute cycle</em>.<span class="intersentencespace"></span> The fetch- execute loop is repeated for as long as the computer is powered on.<span class="intersentencespace"></span> The machine iterates through the entire loop, from step 1 to step 3, over and over again many millions or billions of times per second in order to run programs.<span class="intersentencespace"></span></p>
</li></ol>
<p>Let’s run through the three steps with our example program as shown in Figure 2-9.<span class="intersentencespace"></span> (This example presumes that #500 is already in the program counter.)<span class="intersentencespace"></span> Here’s what the processor does, in order:</p>
<ol>
<li>Fetch the instruction beginning at #500, and load <code>load #12, A</code> into the instruction register.<span class="intersentencespace"></span> Increment the program counter to #502.<span class="intersentencespace"></span>
</li>
<li>Decode <code>load #12, A</code> in the instruction register.<span class="intersentencespace"></span>
</li>
<li>Execute <code>load #12, A</code> from the instruction register, using the memory-
access hardware.<span class="intersentencespace"></span>
</li>
<li>Fetch the instruction beginning at #502, and load <code>load #13, B</code> in the instruction register.<span class="intersentencespace"></span> Increment the program counter to #504.<span class="intersentencespace"></span>
</li>
<li>Decode <code>load #13, B</code> in the instruction register.<span class="intersentencespace"></span>
</li>
<li>Execute <code>load #13, B</code> from the instruction register, using the memory-
access hardware.<span class="intersentencespace"></span>
</li>
<li>Fetch the instruction beginning at #504, and load <code>add A, B, C</code> into the instruction register.<span class="intersentencespace"></span> Increment the program counter to #506.<span class="intersentencespace"></span>
</li>
<li>Decode <code>add A, B, C</code> in the instruction register.<span class="intersentencespace"></span>
</li>
<li>Execute <code>add A, B, C</code> from the instruction register, using the ALU and
register file.<span class="intersentencespace"></span>
</li>
<li>Fetch the instruction at #506, and load <code>store C, #14</code> in the instruction register.<span class="intersentencespace"></span> Increment the program counter to #508.<span class="intersentencespace"></span>
</li>
<li>Decode <code>store C, #14</code> in the instruction register.<span class="intersentencespace"></span>
</li>
<li>Execute <code>store C, #14</code> from the instruction register, using the memory-
access hardware.<span class="intersentencespace"></span>
</li></ol>
<div class="aside" id="aside-note_2-2" data-tralics-id="uid83" data-number="2.2"><div class="heading"><span class="number">Box 2.2.</span> 
</div>
<p class="noindent">To zoom in on the execute steps of the preceding sequence, revisit Chapter 1, and particularly the sections“Refining the File-Clerk Model” on page 6 and “RAM: When the Registers Alone Don’t Cut It” on page 8.<span class="intersentencespace"></span> If you do, you’ll gain a pretty good understanding of what’s involved in executing a program on any machine.<span class="intersentencespace"></span> Sure, there are important machine-specific variations for most of what I’ve presented here, but the general outlines (and even a decent number of the specifics) are the same.</p>

</div></div></div>
<div id="cid11" data-tralics-id="cid11" class="section" data-number="2.3"><h2><a href="#cid11" class="heading hyperref"><span class="number">2.3 </span>The Clock</a></h2>
<p>Steps 1 through 12 in the previous section don’t take an arbitrary amount of time to complete.<span class="intersentencespace"></span> Rather, they’re performed according to the pulse of the clock that governs every action the processor takes.</p>
<p>This clock pulse, which is generated by a <em>clock generator</em> module on the motherboard and is fed into the processor from the outside, times the func- tioning of the processor so that, on the DLW-1 at least, all three steps of the fetch-execute loop are completed in exactly one beat of the clock.<span class="intersentencespace"></span> Thus, the program in Figure 2-9, as I’ve traced its execution in the preceding section, takes exactly four clock beats to finish execution, because a new instruction is fetched on each beat of the clock.</p>
<p>One obvious way to speed up the execution of programs on the DLW-1 would be to speed up its clock generator so that each step takes less time to complete.<span class="intersentencespace"></span> This is generally true of all microprocessors, hence the race among microprocessor designers to build and market chips with ever-higher clock speeds.<span class="intersentencespace"></span> (We’ll talk more about the relationship between clock speed and performance in Chapter 3.)</p>
</div>
<div id="cid12" data-tralics-id="cid12" class="section" data-number="2.4"><h2><a href="#cid12" class="heading hyperref"><span class="number">2.4 </span>Branch Instructions</a></h2>
<p>As I’ve presented it so far, the processor moves through each line in a pro- gram in sequence until it reaches the end of the program, at which point the program’s output is available to the user.</p>
<p>There are certain instructions in the instruction stream, however, that allow the processor to jump to a program line that is out of sequence.<span class="intersentencespace"></span> For instance, by inserting a branch instruction into line 5 of a program, we could cause the processor’s control unit to jump all the way down to line 20 and begin executing there (a forward branch), or we could cause it to jump back up to line 1 (a backward branch).<span class="intersentencespace"></span> Because a program is an ordered sequence of instructions, by including forward and backward branch instructions, we can arbitrarily move about in the program.<span class="intersentencespace"></span> This is a powerful ability, and branches are an essential part of computing.</p>
<p>Rather than thinking about forward or backward branches, it’s more useful for our present purposes to categorize all branches as being one of the following two types: conditional branches or unconditional branches.</p>
<div id="uid84" data-tralics-id="uid84" class="subsection" data-number="2.4.1"><h3><a href="#uid84" class="heading hyperref"><span class="number">2.4.1 </span>Unconditional Branch</a></h3>
<p>An unconditional branch instruction consists of two parts: the branch instruction and the target address.<span class="intersentencespace"></span> </p><div class="code"><div class="highlight"><pre>jump #target
</pre></div></div>
<p>For an unconditional branch, <code>#target</code> can be either an immediate value, like #12, or an address stored in a register, like <code>#D</code>.</p>
<p>Unconditional branches are fairly easy to execute, since all that the computer needs to do upon decoding such a branch in the instruction register is to have the control unit replace the address currently in the program counter with branch’s target address.<span class="intersentencespace"></span> Then the next time the processor goes to fetch the instruction at the address given by the program counter, it’ll fetch the address at the branch target instead.</p>
</div>
<div id="uid85" data-tralics-id="uid85" class="subsection" data-number="2.4.2"><h3><a href="#uid85" class="heading hyperref"><span class="number">2.4.2 </span>Conditional Branch</a></h3>
<p>Though it has the same basic instruction format as the unconditional branch (instruction #target), the <em>conditional branch</em> instruction is a little more complicated, because it involves jumping to the target address only if a certain condition is met.</p>
<p>For example, say we want to jump to a new line of the program only if the previous arithmetic instruction’s result is zero; if the result is nonzero, we want to continue executing normally.<span class="intersentencespace"></span> We would use a conditional branch instruction that first checks to see if the previously executed arithmetic instruction yielded a zero result, and then writes the branch target into the program counter if it did.</p>
<p>Because of such conditional jumps, we need a special register or set of registers in which to store information about the results of arithmetic instructions—information such as whether the previous result was zero or nonzero, positive or negative, and so on.</p>
<p>Different architectures handle this in different ways, but in our DLW-1, this is the function of the <em>processor status word</em> (PSW) register.<span class="intersentencespace"></span> On the DLW-1, every arithmetic operation stores different types of data about its outcome in the PSW upon completion.<span class="intersentencespace"></span> To execute a conditional branch, the DLW-1 must first evaluate the condition on which the branch depends (e.g., “is the previous arithmetic instruction’s result zero?” in the preceding example) by checking the appropriate bit in the PSW to see if that condition is true or false.<span class="intersentencespace"></span> If the branch condition evaluates to true, then the control unit replaces the address in the program counter with the branch target address.<span class="intersentencespace"></span> If the branch condition evaluates to false, then the program counter is left as-is, and the next instruction in the normal program sequence is fetched on the next cycle.</p>
<p>For example, suppose we had just subtracted the number in A from the number in B, and if the result was zero (that is, if the two numbers were equal), we want to jump to the instruction at memory address #106.<span class="intersentencespace"></span> Program 2-2 shows what assembler code for such a conditional branch might look like.</p>
<div class="codelisting" id="code-program_2-2" data-tralics-id="uid86" data-number="2.1"><div class="heading"><span class="number">Listing 2.1:</span> 

<span class="description">Assembler code for a conditional branch</span>
</div>

<div class="code"><div class="highlight"><pre>sub A, B, C   //Subtract the number in register A from the number in register B and store the result in C.
jumpz #106    //Check the PSW, and if the result of the previous instruction was zero, jump to the instruction at address #106. If the result was nonzero, continue on to line 18.
add A, B, C  //Add the numbers in registers A and B and store the result in C.
</pre></div></div></div><p>The <code>jumpz</code> instruction causes the processor to check the PSW to determine whether a certain bit is 1 (true) or 0 (false).<span class="intersentencespace"></span> If the bit is 1, the result of the subtraction instruction was 0 and the program counter must be loaded with the branch target address.<span class="intersentencespace"></span> If the bit is 0, the program counter is incremented to point to the next instruction in sequence (which is the add instruction in line 18).</p>
<p>There are other bits in the PSW that specify other types of information about the result of the previous operation (whether it is positive or negative, is too large for the registers to hold, and so on).<span class="intersentencespace"></span> As such, there are also other types of conditional branch instructions that check these bits.<span class="intersentencespace"></span> For instance, the <code>jumpn</code> instruction jumps to the target address if the result of the preceding arithmetic operation was negative; the <code>jumpo</code> instruction jumps to the target address if the result of the previous operation was too large and overflowed the register.<span class="intersentencespace"></span> If the machine language instruction format of the DLW-1 could accommodate more than eight possible instructions, we could add more types of conditional jumps.</p>
<div id="uid87" data-tralics-id="uid87" class="subsubsection" data-number="2.4.2.1"><h4><a href="#uid87" class="heading">Branch Instructions and the Fetch-Execute Loop</a></h4>
<p>Now that we have looked at the basics of branching, we can modify our three- step summary of program execution to include the possibility of a branch instruction:</p>
<ol>
<li>Fetch the next instruction from the address stored in the program counter, and load that instruction into the instruction register.<span class="intersentencespace"></span> Increment the program counter.<span class="intersentencespace"></span>
</li>
<li>Decode the instruction in the instruction register.<span class="intersentencespace"></span>
</li>
<li>Execute the instruction in the instruction register, using the following rules:
<ul>
<li>If the instruction is an arithmetic instruction, then execute it using the ALU and register file.<span class="intersentencespace"></span>
</li>
<li>If the instruction is a memory-access instruction, then execute it using the memory hardware.<span class="intersentencespace"></span>
</li>
<li>If the instruction is a branch instruction, then execute it using the control unit and the program counter.<span class="intersentencespace"></span> (For a taken branch, write the branch target address into the program counter.)<span class="intersentencespace"></span>
</li></ul>
</li></ol>
<p>In short, you might say that branch instructions allow the programmer to redirect the processor as it travels through the instruction stream.<span class="intersentencespace"></span> Branches point the processor to different sections of the code stream by manipulating its control unit, which, because it contains the instruction register and pro- gram counter, is the rudder of the CPU.</p>
</div>
<div id="uid94" data-tralics-id="uid94" class="subsubsection" data-number="2.4.2.2"><h4><a href="#uid94" class="heading">The Branch Instruction as a Special Type of Load</a></h4>
<p>Recall that an instruction fetch is a special type of <code>load</code> that happens automatically for every instruction and that always takes the address in the program counter as its source and the instruction register as its destination.<span class="intersentencespace"></span> With that in mind, you might think of a branch instruction as a similar kind of <code>load</code>, but under the control of the programmer instead of the CPU. The branch instruction is a load that takes the address specified by <code>#target</code> as its source and the instruction register as its destination.</p>
<p>Like a regular <code>load</code>, a branch instruction can take as its target an address stored in a register.<span class="intersentencespace"></span> In other words, branch instructions can use register-relative addressing just like regular <code>load</code> instructions.<span class="intersentencespace"></span> This capability is useful because it allows the computer to store blocks of code at arbitrary places in memory.<span class="intersentencespace"></span> The programmer doesn’t need to know the address at which a block of code will wind up before writing a branch instruction that jumps to that particular block; all he or she needs is a way to get to the memory location where the operating system, which is responsible for managing memory, has stored the starting address of the desired block of code.</p>
<p>Consider Program 2-3, in which the programmer knows that the operating system has placed the address of the branch target in line 17 in register <code>C</code>.<span class="intersentencespace"></span> Upon reaching line 17, the computer jumps to the address stored in C by copying the contents of C into the instruction register.</p>
<div class="codelisting" id="code-program_2-3" data-tralics-id="uid95" data-number="2.2"><div class="heading"><span class="number">Listing 2.2:</span> 

<span class="description">A conditional branch that uses an address stored in a register</span>
</div>

<div class="code"><div class="highlight"><pre>sub A, B, A   //Subtract the number in register A from the number in register B and store the result in A.
jumpz #C      //Check the PSW, and if the result of the previous instruction was zero, jump to the instruction at the address stored in C. If the result was nonzero, continue on to line 18.
add A, 15, A  //Add 15 to the number in A and store the result in A.
</pre></div></div></div><p>When a programmer uses register-relative addressing with a branch instruction, the operating system must load a certain register with the base address of the <em>code segment</em> in which the program resides.<span class="intersentencespace"></span> Like the data segment, the code segment is a contiguous block of memory cells, but its cells store instructions instead of data.<span class="intersentencespace"></span> So to jump to line 15 in the currently running program, assuming that the operating system has placed the base address of the code segment in C, the programmer could use the following instruction:</p>
<div class="code"><div class="highlight"><pre>jump #(C + 30)  //Jump to the instruction located 30 bytes away from the start of the code segment. (Each instruction is 2 bytes in length, so this puts us at the 15 instruction.)
</pre></div></div>
</div>
<div id="uid96" data-tralics-id="uid96" class="subsubsection" data-number="2.4.2.3"><h4><a href="#uid96" class="heading">Branch Instructions and Labels</a></h4>
<p>In programs written for real-world architectures, branch targets don’t usually take the form of either immediate values or register-relative values.<span class="intersentencespace"></span> Rather, the programmer places a <em>label</em> on the line of code to which he or she wants to jump, and then puts that label in the branch’s target field.<span class="intersentencespace"></span> Program 2-4 shows a portion of assembly language code that uses labels.</p>
<div class="codelisting" id="code-program_2-4" data-tralics-id="uid97" data-number="2.3"><div class="heading"><span class="number">Listing 2.3:</span> 

<span class="description">Assembly language code that uses labels</span>
</div>

<div class="code"><div class="highlight"><pre>      sub A, B, A
      jumpz LBL1
      add A, 15, A
      store A, #(D + 16)
LBL1: add A, B, B
      store B, #(D + 16)
</pre></div></div></div><p>In this example, if the contents of <code>A</code> and <code>B</code> are equal, the computer will jump to the instruction with the label LBL1 and begin executing there, skipping the instructions between the <code>jump</code> and the labeled <code>add</code>.<span class="intersentencespace"></span> Just as the absolute memory addresses used in <code>load</code> and <code>store</code> instructions are modified at load time to fit the location in memory of the program’s data segment, labels like LBL1 are changed at load time into memory addresses that reflect the location in memory of the program’s code segment.</p>
</div></div></div>
<div id="cha-pipelined_execution" data-tralics-id="cid13" class="section" data-number="2.5"><h2><a href="#cha-pipelined_execution" class="heading hyperref"><span class="number">2.5 </span>Excursus: Booting Up</a></h2>
<p>If you’ve been around computers for any length of time, you’ve heard the terms reboot or boot up used in connection with either resetting the computer to its initial state or powering it on initially.<span class="intersentencespace"></span> The term boot is a shortened version of the term bootstrap, which is itself a reference to the seemingly impossible task a computer must perform on start-up, namely, “pulling itself up by its own bootstraps.”</p>
<p>I say “seemingly impossible,” because when a computer is first powered on there is no program in memory, but programs contain the instructions that make the computer run.<span class="intersentencespace"></span> If the processor has no program running when it’s first powered on, then how does it know where to fetch the first instruc- tion from?<span class="intersentencespace"></span> The solution to this dilemma is that the microprocessor, in its power-on default state, is hard-wired to fetch that first instruction from a predetermined address in memory.<span class="intersentencespace"></span> This first instruction, which is loaded into the processor’s instruction register, is the first line of a program called the BIOS that lives in a special set of storage locations—a small read-only memory (ROM) module attached to the computer’s motherboard.<span class="intersentencespace"></span> It’s the job of the BIOS to perform basic tests of the RAM and peripherals in order to verify that everything is working properly.<span class="intersentencespace"></span> Then the boot process can continue.</p>
<p>At the end of the BIOS program lies a jump instruction, the target of which is the location of a <em>bootloader</em> program.<span class="intersentencespace"></span> By using a <code>jump</code>, the BIOS hands off control of the system to this second program, whose job it is to search for and load the computer’s operating system from the hard disk.<span class="intersentencespace"></span> The <em>operating system</em> (OS) loads and unloads all of the other programs that run on the computer, so once the OS is up and running the computer is ready to interact with the user.</p>
<data-label>cha-superscalar_execution</data-label><data-label>cha-the_intel_pentium_and_pentium_pro</data-label><data-label>cha-arm_1</data-label><data-label>cha-intels_pentium_4_vs_arm_2_philosophy</data-label><data-label>cha-intels_pentium_4_vs_arm_2_back_end</data-label><data-label>cha-64_bit_computing_and_x86_64</data-label><data-label>cha-arm_3</data-label><data-label>cha-understanding_caching_and_performance</data-label><data-label>cha-intels_pentium_m_and_core</data-label></div>
    </div>
  </body>
</html>
